{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this notebook, we walk through all the necessary components of running experiments on LIBERO, and some common usage such as defining your own algorithm and policy architectures in the codebase.\n",
    "\n",
    "1. Dataset preparation for your algorithms\n",
    "2. Write your own algorithm\n",
    "    - Subclassing from `Sequential` base class\n",
    "3. Write your own model\n",
    "4. Write your training loop\n",
    "5. Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24770/2563292850.py:18: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path=\"../libero/configs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'color_aug': { 'network': 'BatchWiseImgColorJitterAug',\n",
      "                 'network_kwargs': { 'brightness': 0.3,\n",
      "                                     'contrast': 0.3,\n",
      "                                     'epsilon': 0.1,\n",
      "                                     'hue': 0.3,\n",
      "                                     'input_shape': None,\n",
      "                                     'saturation': 0.3}},\n",
      "  'embed_size': 64,\n",
      "  'extra_hidden_size': 128,\n",
      "  'extra_num_layers': 0,\n",
      "  'image_encoder': { 'network': 'ResnetEncoder',\n",
      "                     'network_kwargs': { 'freeze': False,\n",
      "                                         'language_fusion': 'film',\n",
      "                                         'no_stride': False,\n",
      "                                         'pretrained': False,\n",
      "                                         'remove_layer_num': 4}},\n",
      "  'language_encoder': { 'network': 'MLPEncoder',\n",
      "                        'network_kwargs': { 'hidden_size': 128,\n",
      "                                            'input_size': 768,\n",
      "                                            'num_layers': 1,\n",
      "                                            'output_size': 128}},\n",
      "  'policy_head': { 'loss_kwargs': {'loss_coef': 1.0},\n",
      "                   'network': 'GMMHead',\n",
      "                   'network_kwargs': { 'activation': 'softplus',\n",
      "                                       'hidden_size': 1024,\n",
      "                                       'low_eval_noise': False,\n",
      "                                       'min_std': 0.0001,\n",
      "                                       'num_layers': 2,\n",
      "                                       'num_modes': 5}},\n",
      "  'policy_type': 'BCTransformerPolicy',\n",
      "  'temporal_position_encoding': { 'network': 'SinusoidalPositionEncoding',\n",
      "                                  'network_kwargs': { 'factor_ratio': None,\n",
      "                                                      'input_size': None,\n",
      "                                                      'inv_freq_factor': 10}},\n",
      "  'transformer_dropout': 0.1,\n",
      "  'transformer_head_output_size': 64,\n",
      "  'transformer_input_size': None,\n",
      "  'transformer_max_seq_len': 10,\n",
      "  'transformer_mlp_hidden_size': 256,\n",
      "  'transformer_num_heads': 6,\n",
      "  'transformer_num_layers': 4,\n",
      "  'translation_aug': { 'network': 'TranslationAug',\n",
      "                       'network_kwargs': { 'input_shape': None,\n",
      "                                           'translation': 8}}}\n",
      "('Note that the number of epochs used in this example is intentionally reduced '\n",
      " 'to 5.')\n",
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: rgb with keys: ['eye_in_hand_rgb', 'agentview_rgb']\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: low_dim with keys: ['gripper_states', 'joint_states']\n",
      "SequenceDataset: loading dataset into memory...\n",
      "100%|██████████| 50/50 [00:00<00:00, 1126.19it/s]\n",
      "SequenceDataset: loading dataset into memory...\n",
      "100%|██████████| 50/50 [00:00<00:00, 1162.72it/s]\n",
      "SequenceDataset: loading dataset into memory...\n",
      "100%|██████████| 50/50 [00:00<00:00, 1175.77it/s]\n",
      "SequenceDataset: loading dataset into memory...\n",
      "100%|██████████| 50/50 [00:00<00:00, 1206.08it/s]\n",
      "SequenceDataset: loading dataset into memory...\n",
      "100%|██████████| 50/50 [00:00<00:00, 1134.37it/s]\n",
      "SequenceDataset: loading dataset into memory...\n",
      "100%|██████████| 50/50 [00:00<00:00, 967.75it/s]\n",
      "SequenceDataset: loading dataset into memory...\n",
      "100%|██████████| 50/50 [00:00<00:00, 1178.42it/s]\n",
      "SequenceDataset: loading dataset into memory...\n",
      "100%|██████████| 50/50 [00:00<00:00, 1222.58it/s]\n",
      "SequenceDataset: loading dataset into memory...\n",
      "100%|██████████| 50/50 [00:00<00:00, 1164.09it/s]\n",
      "SequenceDataset: loading dataset into memory...\n",
      "100%|██████████| 50/50 [00:00<00:00, 1151.78it/s]\n"
     ]
    }
   ],
   "source": [
    "from hydra import compose, initialize\n",
    "\n",
    "from libero.libero import benchmark, get_libero_path\n",
    "import hydra\n",
    "import pprint\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['PYOPENGL_PLATFORM'] = 'egl'\n",
    "from omegaconf import OmegaConf\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "from libero.libero.benchmark import get_benchmark\n",
    "from libero.lifelong.datasets import (GroupedTaskDataset, SequenceVLDataset, get_dataset)\n",
    "from libero.lifelong.utils import (get_task_embs, safe_device, create_experiment_dir)\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "\n",
    "### load the default hydra config\n",
    "initialize(config_path=\"../libero/configs\")\n",
    "hydra_cfg = compose(config_name=\"config\")\n",
    "yaml_config = OmegaConf.to_yaml(hydra_cfg)\n",
    "cfg = EasyDict(yaml.safe_load(yaml_config))\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "pp.pprint(cfg.policy)\n",
    "\n",
    "# prepare lifelong learning\n",
    "cfg.folder = get_libero_path(\"datasets\")\n",
    "cfg.bddl_folder = get_libero_path(\"bddl_files\")\n",
    "cfg.init_states_folder = get_libero_path(\"init_states\")\n",
    "cfg.eval.num_procs = 1\n",
    "cfg.eval.n_eval = 5\n",
    "\n",
    "cfg.train.n_epochs = 25\n",
    "\n",
    "pp.pprint(f\"Note that the number of epochs used in this example is intentionally reduced to 5.\")\n",
    "\n",
    "task_order = cfg.data.task_order_index # can be from {0 .. 21}, default to 0, which is [task 0, 1, 2 ...]\n",
    "cfg.benchmark_name = \"libero_object\" # can be from {\"libero_spatial\", \"libero_object\", \"libero_goal\", \"libero_10\"}\n",
    "benchmark = get_benchmark(cfg.benchmark_name)(task_order)\n",
    "\n",
    "# prepare datasets from the benchmark\n",
    "datasets = []\n",
    "descriptions = []\n",
    "shape_meta = None\n",
    "n_tasks = benchmark.n_tasks\n",
    "\n",
    "for i in range(n_tasks):\n",
    "    # currently we assume tasks from same benchmark have the same shape_meta\n",
    "    task_i_dataset, shape_meta = get_dataset(\n",
    "            dataset_path=os.path.join(cfg.folder, benchmark.get_task_demonstration(i)),\n",
    "            obs_modality=cfg.data.obs.modality,\n",
    "            initialize_obs_utils=(i==0),\n",
    "            seq_len=cfg.data.seq_len,\n",
    "    )\n",
    "    # add language to the vision dataset, hence we call vl_dataset\n",
    "    descriptions.append(benchmark.get_task(i).language)\n",
    "    datasets.append(task_i_dataset)\n",
    "\n",
    "task_embs = get_task_embs(cfg, descriptions)\n",
    "benchmark.set_task_embs(task_embs)\n",
    "\n",
    "datasets = [SequenceVLDataset(ds, emb) for (ds, emb) in zip(datasets, task_embs)]\n",
    "n_demos = [data.n_demos for data in datasets]\n",
    "n_sequences = [data.total_num_sequences for data in datasets]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write your own policy architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robomimic.utils.tensor_utils as TensorUtils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from libero.lifelong.models.modules.rgb_modules import *\n",
    "from libero.lifelong.models.modules.language_modules import *\n",
    "from libero.lifelong.models.base_policy import BasePolicy\n",
    "from libero.lifelong.models.policy_head import *\n",
    "from libero.lifelong.models.modules.transformer_modules import *\n",
    "\n",
    "###############################################################################\n",
    "#\n",
    "# A model handling extra input modalities besides images at time t.\n",
    "#\n",
    "###############################################################################\n",
    "\n",
    "class ExtraModalityTokens(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        use_joint=False,\n",
    "        use_gripper=False,\n",
    "        use_ee=False,\n",
    "        extra_num_layers=0,\n",
    "        extra_hidden_size=64,\n",
    "        extra_embedding_size=32,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This is a class that maps all extra modality inputs into tokens of the same size\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.use_joint = use_joint\n",
    "        self.use_gripper = use_gripper\n",
    "        self.use_ee = use_ee\n",
    "        self.extra_embedding_size = extra_embedding_size\n",
    "\n",
    "        joint_states_dim = 7\n",
    "        gripper_states_dim = 2\n",
    "        ee_dim = 3\n",
    "\n",
    "        self.num_extra = int(use_joint) + int(use_gripper) + int(use_ee)\n",
    "\n",
    "        extra_low_level_feature_dim = (\n",
    "            int(use_joint) * joint_states_dim\n",
    "            + int(use_gripper) * gripper_states_dim\n",
    "            + int(use_ee) * ee_dim\n",
    "        )\n",
    "\n",
    "        assert extra_low_level_feature_dim > 0, \"[error] no extra information\"\n",
    "\n",
    "        self.extra_encoders = {}\n",
    "\n",
    "        def generate_proprio_mlp_fn(modality_name, extra_low_level_feature_dim):\n",
    "            assert extra_low_level_feature_dim > 0  # we indeed have extra information\n",
    "            if extra_num_layers > 0:\n",
    "                layers = [nn.Linear(extra_low_level_feature_dim, extra_hidden_size)]\n",
    "                for i in range(1, extra_num_layers):\n",
    "                    layers += [\n",
    "                        nn.Linear(extra_hidden_size, extra_hidden_size),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                    ]\n",
    "                layers += [nn.Linear(extra_hidden_size, extra_embedding_size)]\n",
    "            else:\n",
    "                layers = [nn.Linear(extra_low_level_feature_dim, extra_embedding_size)]\n",
    "\n",
    "            self.proprio_mlp = nn.Sequential(*layers)\n",
    "            self.extra_encoders[modality_name] = {\"encoder\": self.proprio_mlp}\n",
    "\n",
    "        for (proprio_dim, use_modality, modality_name) in [\n",
    "            (joint_states_dim, self.use_joint, \"joint_states\"),\n",
    "            (gripper_states_dim, self.use_gripper, \"gripper_states\"),\n",
    "            (ee_dim, self.use_ee, \"ee_states\"),\n",
    "        ]:\n",
    "\n",
    "            if use_modality:\n",
    "                generate_proprio_mlp_fn(modality_name, proprio_dim)\n",
    "\n",
    "        self.encoders = nn.ModuleList(\n",
    "            [x[\"encoder\"] for x in self.extra_encoders.values()]\n",
    "        )\n",
    "\n",
    "    def forward(self, obs_dict):\n",
    "        \"\"\"\n",
    "        obs_dict: {\n",
    "            (optional) joint_stats: (B, T, 7),\n",
    "            (optional) gripper_states: (B, T, 2),\n",
    "            (optional) ee: (B, T, 3)\n",
    "        }\n",
    "        map above to a latent vector of shape (B, T, H)\n",
    "        \"\"\"\n",
    "        tensor_list = []\n",
    "\n",
    "        for (use_modality, modality_name) in [\n",
    "            (self.use_joint, \"joint_states\"),\n",
    "            (self.use_gripper, \"gripper_states\"),\n",
    "            (self.use_ee, \"ee_states\"),\n",
    "        ]:\n",
    "\n",
    "            if use_modality:\n",
    "                tensor_list.append(\n",
    "                    self.extra_encoders[modality_name][\"encoder\"](\n",
    "                        obs_dict[modality_name]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        x = torch.stack(tensor_list, dim=-2)\n",
    "        return x\n",
    "\n",
    "###############################################################################\n",
    "#\n",
    "# A Transformer policy\n",
    "#\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "class MyTransformerPolicy(BasePolicy):\n",
    "    \"\"\"\n",
    "    Input: (o_{t-H}, ... , o_t)\n",
    "    Output: a_t or distribution of a_t\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg, shape_meta):\n",
    "        super().__init__(cfg, shape_meta)\n",
    "        policy_cfg = cfg.policy\n",
    "\n",
    "        ### 1. encode image\n",
    "        embed_size = policy_cfg.embed_size\n",
    "        transformer_input_sizes = []\n",
    "        self.image_encoders = {}\n",
    "        for name in shape_meta[\"all_shapes\"].keys():\n",
    "            if \"rgb\" in name or \"depth\" in name:\n",
    "                kwargs = policy_cfg.image_encoder.network_kwargs\n",
    "                kwargs.input_shape = shape_meta[\"all_shapes\"][name]\n",
    "                kwargs.output_size = embed_size\n",
    "                kwargs.language_dim = (\n",
    "                    policy_cfg.language_encoder.network_kwargs.input_size\n",
    "                )\n",
    "                self.image_encoders[name] = {\n",
    "                    \"input_shape\": shape_meta[\"all_shapes\"][name],\n",
    "                    \"encoder\": eval(policy_cfg.image_encoder.network)(**kwargs),\n",
    "                }\n",
    "\n",
    "        self.encoders = nn.ModuleList(\n",
    "            [x[\"encoder\"] for x in self.image_encoders.values()]\n",
    "        )\n",
    "\n",
    "        ### 2. encode language\n",
    "        policy_cfg.language_encoder.network_kwargs.output_size = embed_size\n",
    "        self.language_encoder = eval(policy_cfg.language_encoder.network)(\n",
    "            **policy_cfg.language_encoder.network_kwargs\n",
    "        )\n",
    "\n",
    "        ### 3. encode extra information (e.g. gripper, joint_state)\n",
    "        self.extra_encoder = ExtraModalityTokens(\n",
    "            use_joint=cfg.data.use_joint,\n",
    "            use_gripper=cfg.data.use_gripper,\n",
    "            use_ee=cfg.data.use_ee,\n",
    "            extra_num_layers=policy_cfg.extra_num_layers,\n",
    "            extra_hidden_size=policy_cfg.extra_hidden_size,\n",
    "            extra_embedding_size=embed_size,\n",
    "        )\n",
    "\n",
    "        ### 4. define temporal transformer\n",
    "        policy_cfg.temporal_position_encoding.network_kwargs.input_size = embed_size\n",
    "        self.temporal_position_encoding_fn = eval(\n",
    "            policy_cfg.temporal_position_encoding.network\n",
    "        )(**policy_cfg.temporal_position_encoding.network_kwargs)\n",
    "\n",
    "        self.temporal_transformer = TransformerDecoder(\n",
    "            input_size=embed_size,\n",
    "            num_layers=policy_cfg.transformer_num_layers,\n",
    "            num_heads=policy_cfg.transformer_num_heads,\n",
    "            head_output_size=policy_cfg.transformer_head_output_size,\n",
    "            mlp_hidden_size=policy_cfg.transformer_mlp_hidden_size,\n",
    "            dropout=policy_cfg.transformer_dropout,\n",
    "        )\n",
    "\n",
    "        policy_head_kwargs = policy_cfg.policy_head.network_kwargs\n",
    "        policy_head_kwargs.input_size = embed_size\n",
    "        policy_head_kwargs.output_size = shape_meta[\"ac_dim\"]\n",
    "\n",
    "        self.policy_head = eval(policy_cfg.policy_head.network)(\n",
    "            **policy_cfg.policy_head.loss_kwargs,\n",
    "            **policy_cfg.policy_head.network_kwargs\n",
    "        )\n",
    "\n",
    "        self.latent_queue = []\n",
    "        self.max_seq_len = policy_cfg.transformer_max_seq_len\n",
    "\n",
    "    def temporal_encode(self, x):\n",
    "        pos_emb = self.temporal_position_encoding_fn(x)\n",
    "        x = x + pos_emb.unsqueeze(1)  # (B, T, num_modality, E)\n",
    "        sh = x.shape\n",
    "        self.temporal_transformer.compute_mask(x.shape)\n",
    "\n",
    "        x = TensorUtils.join_dimensions(x, 1, 2)  # (B, T*num_modality, E)\n",
    "        x = self.temporal_transformer(x)\n",
    "        x = x.reshape(*sh)\n",
    "        return x[:, :, 0]  # (B, T, E)\n",
    "\n",
    "    def spatial_encode(self, data):\n",
    "        # 1. encode extra\n",
    "        extra = self.extra_encoder(data[\"obs\"])  # (B, T, num_extra, E)\n",
    "\n",
    "        # 2. encode language, treat it as action token\n",
    "        B, T = extra.shape[:2]\n",
    "        text_encoded = self.language_encoder(data)  # (B, E)\n",
    "        text_encoded = text_encoded.view(B, 1, 1, -1).expand(\n",
    "            -1, T, -1, -1\n",
    "        )  # (B, T, 1, E)\n",
    "        encoded = [text_encoded, extra]\n",
    "\n",
    "        # 3. encode image\n",
    "        for img_name in self.image_encoders.keys():\n",
    "            x = data[\"obs\"][img_name]\n",
    "            B, T, C, H, W = x.shape\n",
    "            img_encoded = self.image_encoders[img_name][\"encoder\"](\n",
    "                x.reshape(B * T, C, H, W),\n",
    "                langs=data[\"task_emb\"]\n",
    "                .reshape(B, 1, -1)\n",
    "                .repeat(1, T, 1)\n",
    "                .reshape(B * T, -1),\n",
    "            ).view(B, T, 1, -1)\n",
    "            encoded.append(img_encoded)\n",
    "        encoded = torch.cat(encoded, -2)  # (B, T, num_modalities, E)\n",
    "        return encoded\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.spatial_encode(data)\n",
    "        x = self.temporal_encode(x)\n",
    "        dist = self.policy_head(x)\n",
    "        return dist\n",
    "\n",
    "    def get_action(self, data):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            data = self.preprocess_input(data, train_mode=False)\n",
    "            x = self.spatial_encode(data)\n",
    "            self.latent_queue.append(x)\n",
    "            if len(self.latent_queue) > self.max_seq_len:\n",
    "                self.latent_queue.pop(0)\n",
    "            x = torch.cat(self.latent_queue, dim=1)  # (B, T, H_all)\n",
    "            x = self.temporal_encode(x)\n",
    "            dist = self.policy_head(x[:, -1])\n",
    "        action = dist.sample().detach().cpu()\n",
    "        return action.view(action.shape[0], -1).numpy()\n",
    "\n",
    "    def reset(self):\n",
    "        self.latent_queue = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write your own lifelong learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (__init__.py:7)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (__init__.py:8)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/yifengz/workspace/robosuite-master/robosuite/scripts/setup_macros.py (__init__.py:9)\n"
     ]
    }
   ],
   "source": [
    "from libero.lifelong.algos.base import Sequential\n",
    "\n",
    "### All lifelong learning algorithm should inherit the Sequential algorithm super class\n",
    "\n",
    "class MyLifelongAlgo(Sequential):\n",
    "    \"\"\"\n",
    "    The experience replay policy.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n_tasks,\n",
    "                 cfg,\n",
    "                 **policy_kwargs):\n",
    "        super().__init__(n_tasks=n_tasks, cfg=cfg, **policy_kwargs)\n",
    "        # define the learning policy\n",
    "        self.datasets = []\n",
    "        self.policy = eval(cfg.policy.policy_type)(cfg, cfg.shape_meta)\n",
    "\n",
    "    def start_task(self, task):\n",
    "        # what to do at the beginning of a new task\n",
    "        super().start_task(task)\n",
    "\n",
    "    def end_task(self, dataset, task_id, benchmark):\n",
    "        # what to do when finish learning a new task\n",
    "        self.datasets.append(dataset)\n",
    "\n",
    "    def observe(self, data):\n",
    "        # how the algorithm observes a data and returns a loss to be optimized\n",
    "        loss = super().observe(data)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Write your training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment directory is:  ./experiments/libero_object/MyLifelongAlgo/MyTransformerPolicy_seed10000/run_006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifengz/.pyenv/versions/3.8.5/envs/new-continual-learning/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/yifengz/.pyenv/versions/3.8.5/envs/new-continual-learning/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/home/yifengz/.pyenv/versions/3.8.5/envs/new-continual-learning/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: the number of epochs used in this example is intentionally reduced to 30 for simplicity.\n",
      "NOTE: the number of evaluation episodes used in this example is intentionally reduced to 5 for simplicity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Epoch:   0 | train loss:  5.45 | time: 0.64\n",
      "[info] evaluate task 0 takes 109.5 seconds\n",
      "[info] Epoch:   0 | succ: 0.00 ± 0.00 | best succ: 0.0 | succ. AoC 0.00 | time: 1.82\n",
      "[info] Epoch:   1 | train loss: -6.00 | time: 1.32\n",
      "[info] Epoch:   2 | train loss: -12.35 | time: 1.31\n",
      "[info] Epoch:   3 | train loss: -14.18 | time: 1.30\n",
      "[info] Epoch:   4 | train loss: -14.78 | time: 1.30\n",
      "[info] Epoch:   5 | train loss: -15.23 | time: 1.28\n",
      "[info] evaluate task 0 takes 105.7 seconds\n",
      "[info] Epoch:   5 | succ: 0.00 ± 0.00 | best succ: 0.0 | succ. AoC 0.00 | time: 1.76\n",
      "[info] Epoch:   6 | train loss: -15.64 | time: 1.22\n",
      "[info] Epoch:   7 | train loss: -16.03 | time: 1.22\n",
      "[info] Epoch:   8 | train loss: -16.58 | time: 1.22\n",
      "[info] Epoch:   9 | train loss: -16.81 | time: 1.22\n",
      "[info] Epoch:  10 | train loss: -17.12 | time: 1.22\n",
      "[info] evaluate task 0 takes 68.6 seconds\n",
      "[info] Epoch:  10 | succ: 0.60 ± 0.43 | best succ: 0.6 | succ. AoC 0.20 | time: 1.14\n",
      "[info] Epoch:  11 | train loss: -17.29 | time: 1.22\n",
      "[info] Epoch:  12 | train loss: -17.54 | time: 1.22\n",
      "[info] Epoch:  13 | train loss: -17.82 | time: 1.22\n",
      "[info] Epoch:  14 | train loss: -18.08 | time: 1.23\n",
      "[info] Epoch:  15 | train loss: -18.24 | time: 1.23\n",
      "[info] evaluate task 0 takes 62.2 seconds\n",
      "[info] Epoch:  15 | succ: 0.80 ± 0.35 | best succ: 0.8 | succ. AoC 0.35 | time: 1.04\n",
      "[info] Epoch:  16 | train loss: -18.42 | time: 1.22\n",
      "[info] Epoch:  17 | train loss: -18.62 | time: 1.22\n",
      "[info] Epoch:  18 | train loss: -18.84 | time: 1.22\n",
      "[info] Epoch:  19 | train loss: -19.02 | time: 1.22\n",
      "[info] Epoch:  20 | train loss: -19.19 | time: 1.22\n",
      "[info] evaluate task 0 takes 63.3 seconds\n",
      "[info] Epoch:  20 | succ: 0.80 ± 0.35 | best succ: 0.8 | succ. AoC 0.44 | time: 1.05\n",
      "[info] Epoch:  21 | train loss: -19.29 | time: 1.22\n",
      "[info] Epoch:  22 | train loss: -19.42 | time: 1.22\n",
      "[info] Epoch:  23 | train loss: -19.51 | time: 1.22\n",
      "[info] Epoch:  24 | train loss: -19.62 | time: 1.22\n",
      "[info] Epoch:  25 | train loss: -19.65 | time: 1.22\n",
      "[info] evaluate task 0 takes 108.8 seconds\n",
      "[info] Epoch:  25 | succ: 0.00 ± 0.00 | best succ: 0.8 | succ. AoC 0.50 | time: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [41:46<6:15:58, 2506.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] evaluate task 0 takes 72.8 seconds\n",
      "[info] Epoch:   0 | train loss: -4.56 | time: 0.52\n",
      "[info] evaluate task 1 takes 109.4 seconds\n",
      "[info] Epoch:   0 | succ: 0.00 ± 0.00 | best succ: 0.0 | succ. AoC 0.00 | time: 1.82\n",
      "[info] Epoch:   1 | train loss: -15.55 | time: 1.11\n",
      "[info] Epoch:   2 | train loss: -16.33 | time: 1.12\n",
      "[info] Epoch:   3 | train loss: -16.65 | time: 1.12\n",
      "[info] Epoch:   4 | train loss: -16.91 | time: 1.12\n",
      "[info] Epoch:   5 | train loss: -17.16 | time: 1.12\n",
      "[info] evaluate task 1 takes 100.9 seconds\n",
      "[info] Epoch:   5 | succ: 0.20 ± 0.35 | best succ: 0.2 | succ. AoC 0.10 | time: 1.68\n",
      "[info] Epoch:   6 | train loss: -17.32 | time: 1.12\n",
      "[info] Epoch:   7 | train loss: -17.52 | time: 1.12\n",
      "[info] Epoch:   8 | train loss: -17.79 | time: 1.12\n",
      "[info] Epoch:   9 | train loss: -17.99 | time: 1.13\n",
      "[info] Epoch:  10 | train loss: -18.20 | time: 1.13\n",
      "[info] evaluate task 1 takes 68.1 seconds\n",
      "[info] Epoch:  10 | succ: 0.60 ± 0.43 | best succ: 0.6 | succ. AoC 0.27 | time: 1.14\n",
      "[info] Epoch:  11 | train loss: -18.49 | time: 1.12\n",
      "[info] Epoch:  12 | train loss: -18.73 | time: 1.13\n",
      "[info] Epoch:  13 | train loss: -18.94 | time: 1.12\n",
      "[info] Epoch:  14 | train loss: -19.16 | time: 1.13\n",
      "[info] Epoch:  15 | train loss: -19.41 | time: 1.13\n",
      "[info] evaluate task 1 takes 40.1 seconds\n",
      "[info] Epoch:  15 | succ: 1.00 ± 0.00 | best succ: 1.0 | succ. AoC 0.45 | time: 0.67\n",
      "[info] Epoch:  16 | train loss: -19.62 | time: 1.12\n",
      "[info] Epoch:  17 | train loss: -19.79 | time: 1.13\n",
      "[info] Epoch:  18 | train loss: -19.98 | time: 1.13\n",
      "[info] Epoch:  19 | train loss: -20.18 | time: 1.13\n",
      "[info] Epoch:  20 | train loss: -20.32 | time: 1.13\n",
      "[info] evaluate task 1 takes 66.0 seconds\n",
      "[info] Epoch:  20 | succ: 0.60 ± 0.43 | best succ: 1.0 | succ. AoC 0.56 | time: 1.10\n",
      "[info] Epoch:  21 | train loss: -20.45 | time: 1.12\n",
      "[info] Epoch:  22 | train loss: -20.59 | time: 1.13\n",
      "[info] Epoch:  23 | train loss: -20.66 | time: 1.13\n",
      "[info] Epoch:  24 | train loss: -20.78 | time: 1.13\n",
      "[info] Epoch:  25 | train loss: -20.83 | time: 1.13\n",
      "[info] evaluate task 1 takes 73.4 seconds\n",
      "[info] Epoch:  25 | succ: 0.60 ± 0.43 | best succ: 1.0 | succ. AoC 0.63 | time: 1.22\n",
      "[info] evaluate task 0 takes 104.8 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [1:21:19<5:23:42, 2427.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] evaluate task 1 takes 52.7 seconds\n",
      "[info] Epoch:   0 | train loss: -9.45 | time: 0.48\n",
      "[info] evaluate task 2 takes 109.7 seconds\n",
      "[info] Epoch:   0 | succ: 0.00 ± 0.00 | best succ: 0.0 | succ. AoC 0.00 | time: 1.83\n",
      "[info] Epoch:   1 | train loss: -16.82 | time: 1.03\n",
      "[info] Epoch:   2 | train loss: -17.54 | time: 1.04\n",
      "[info] Epoch:   3 | train loss: -17.92 | time: 1.04\n",
      "[info] Epoch:   4 | train loss: -18.20 | time: 1.04\n",
      "[info] Epoch:   5 | train loss: -18.40 | time: 1.04\n",
      "[info] evaluate task 2 takes 49.9 seconds\n",
      "[info] Epoch:   5 | succ: 0.80 ± 0.35 | best succ: 0.8 | succ. AoC 0.40 | time: 0.83\n",
      "[info] Epoch:   6 | train loss: -18.63 | time: 1.04\n",
      "[info] Epoch:   7 | train loss: -18.92 | time: 1.04\n",
      "[info] Epoch:   8 | train loss: -19.14 | time: 1.04\n",
      "[info] Epoch:   9 | train loss: -19.38 | time: 1.04\n",
      "[info] Epoch:  10 | train loss: -19.56 | time: 1.04\n",
      "[info] evaluate task 2 takes 68.7 seconds\n",
      "[info] Epoch:  10 | succ: 0.60 ± 0.43 | best succ: 0.8 | succ. AoC 0.53 | time: 1.14\n",
      "[info] Epoch:  11 | train loss: -19.80 | time: 1.04\n",
      "[info] Epoch:  12 | train loss: -20.00 | time: 1.04\n",
      "[info] Epoch:  13 | train loss: -20.23 | time: 1.04\n",
      "[info] Epoch:  14 | train loss: -20.45 | time: 1.04\n",
      "[info] Epoch:  15 | train loss: -20.64 | time: 1.04\n",
      "[info] evaluate task 2 takes 80.8 seconds\n",
      "[info] Epoch:  15 | succ: 0.40 ± 0.43 | best succ: 0.8 | succ. AoC 0.60 | time: 1.35\n",
      "[info] Epoch:  16 | train loss: -20.84 | time: 1.03\n",
      "[info] Epoch:  17 | train loss: -21.06 | time: 1.04\n",
      "[info] Epoch:  18 | train loss: -21.23 | time: 1.04\n",
      "[info] Epoch:  19 | train loss: -21.34 | time: 1.04\n",
      "[info] Epoch:  20 | train loss: -21.51 | time: 1.04\n",
      "[info] evaluate task 2 takes 93.5 seconds\n",
      "[info] Epoch:  20 | succ: 0.20 ± 0.35 | best succ: 0.8 | succ. AoC 0.64 | time: 1.56\n",
      "[info] Epoch:  21 | train loss: -21.63 | time: 1.04\n",
      "[info] Epoch:  22 | train loss: -21.76 | time: 1.04\n",
      "[info] Epoch:  23 | train loss: -21.83 | time: 1.04\n",
      "[info] Epoch:  24 | train loss: -21.94 | time: 1.04\n",
      "[info] Epoch:  25 | train loss: -21.99 | time: 1.05\n",
      "[info] evaluate task 2 takes 79.4 seconds\n",
      "[info] Epoch:  25 | succ: 0.40 ± 0.43 | best succ: 0.8 | succ. AoC 0.67 | time: 1.32\n",
      "[info] evaluate task 0 takes 108.2 seconds\n",
      "[info] evaluate task 1 takes 108.6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [2:01:15<4:41:34, 2413.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] evaluate task 2 takes 50.7 seconds\n",
      "[info] Epoch:   0 | train loss: -13.37 | time: 0.53\n",
      "[info] evaluate task 3 takes 109.4 seconds\n",
      "[info] Epoch:   0 | succ: 0.00 ± 0.00 | best succ: 0.0 | succ. AoC 0.00 | time: 1.82\n",
      "[info] Epoch:   1 | train loss: -16.90 | time: 1.14\n",
      "[info] Epoch:   2 | train loss: -17.55 | time: 1.14\n",
      "[info] Epoch:   3 | train loss: -17.89 | time: 1.15\n",
      "[info] Epoch:   4 | train loss: -18.27 | time: 1.15\n",
      "[info] Epoch:   5 | train loss: -18.57 | time: 1.15\n",
      "[info] evaluate task 3 takes 89.3 seconds\n",
      "[info] Epoch:   5 | succ: 0.20 ± 0.35 | best succ: 0.2 | succ. AoC 0.10 | time: 1.49\n",
      "[info] Epoch:   6 | train loss: -18.87 | time: 1.14\n",
      "[info] Epoch:   7 | train loss: -19.15 | time: 1.15\n",
      "[info] Epoch:   8 | train loss: -19.43 | time: 1.15\n",
      "[info] Epoch:   9 | train loss: -19.69 | time: 1.15\n",
      "[info] Epoch:  10 | train loss: -19.93 | time: 1.15\n",
      "[info] evaluate task 3 takes 90.7 seconds\n",
      "[info] Epoch:  10 | succ: 0.20 ± 0.35 | best succ: 0.2 | succ. AoC 0.13 | time: 1.51\n",
      "[info] Epoch:  11 | train loss: -20.14 | time: 1.15\n",
      "[info] Epoch:  12 | train loss: -20.42 | time: 1.15\n",
      "[info] Epoch:  13 | train loss: -20.63 | time: 1.15\n",
      "[info] Epoch:  14 | train loss: -20.93 | time: 1.15\n",
      "[info] Epoch:  15 | train loss: -21.06 | time: 1.16\n",
      "[info] evaluate task 3 takes 78.1 seconds\n",
      "[info] Epoch:  15 | succ: 0.40 ± 0.43 | best succ: 0.4 | succ. AoC 0.20 | time: 1.30\n",
      "[info] Epoch:  16 | train loss: -21.28 | time: 1.15\n",
      "[info] Epoch:  17 | train loss: -21.54 | time: 1.15\n",
      "[info] Epoch:  18 | train loss: -21.69 | time: 1.16\n",
      "[info] Epoch:  19 | train loss: -21.90 | time: 1.16\n",
      "[info] Epoch:  20 | train loss: -22.00 | time: 1.16\n",
      "[info] evaluate task 3 takes 64.4 seconds\n",
      "[info] Epoch:  20 | succ: 0.60 ± 0.43 | best succ: 0.6 | succ. AoC 0.28 | time: 1.07\n",
      "[info] Epoch:  21 | train loss: -22.18 | time: 1.15\n",
      "[info] Epoch:  22 | train loss: -22.30 | time: 1.15\n",
      "[info] Epoch:  23 | train loss: -22.38 | time: 1.16\n",
      "[info] Epoch:  24 | train loss: -22.44 | time: 1.15\n",
      "[info] Epoch:  25 | train loss: -22.52 | time: 1.16\n",
      "[info] evaluate task 3 takes 63.9 seconds\n",
      "[info] Epoch:  25 | succ: 0.60 ± 0.43 | best succ: 0.6 | succ. AoC 0.33 | time: 1.07\n",
      "[info] evaluate task 0 takes 104.3 seconds\n",
      "[info] evaluate task 1 takes 105.9 seconds\n",
      "[info] evaluate task 2 takes 90.2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [2:46:12<4:12:32, 2525.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] evaluate task 3 takes 64.2 seconds\n",
      "[info] Epoch:   0 | train loss:  5.97 | time: 0.58\n",
      "[info] evaluate task 4 takes 104.8 seconds\n",
      "[info] Epoch:   0 | succ: 0.00 ± 0.00 | best succ: 0.0 | succ. AoC 0.00 | time: 1.75\n",
      "[info] Epoch:   1 | train loss: -16.72 | time: 1.25\n",
      "[info] Epoch:   2 | train loss: -17.93 | time: 1.26\n",
      "[info] Epoch:   3 | train loss: -18.50 | time: 1.26\n",
      "[info] Epoch:   4 | train loss: -18.88 | time: 1.26\n",
      "[info] Epoch:   5 | train loss: -19.33 | time: 1.26\n",
      "[info] evaluate task 4 takes 97.5 seconds\n",
      "[info] Epoch:   5 | succ: 0.20 ± 0.35 | best succ: 0.2 | succ. AoC 0.10 | time: 1.63\n",
      "[info] Epoch:   6 | train loss: -19.63 | time: 1.25\n",
      "[info] Epoch:   7 | train loss: -19.99 | time: 1.26\n",
      "[info] Epoch:   8 | train loss: -20.30 | time: 1.27\n",
      "[info] Epoch:   9 | train loss: -20.58 | time: 1.27\n",
      "[info] Epoch:  10 | train loss: -20.83 | time: 1.27\n",
      "[info] evaluate task 4 takes 51.9 seconds\n",
      "[info] Epoch:  10 | succ: 0.80 ± 0.35 | best succ: 0.8 | succ. AoC 0.33 | time: 0.87\n",
      "[info] Epoch:  11 | train loss: -21.13 | time: 1.26\n",
      "[info] Epoch:  12 | train loss: -21.44 | time: 1.26\n",
      "[info] Epoch:  13 | train loss: -21.69 | time: 1.27\n",
      "[info] Epoch:  14 | train loss: -21.90 | time: 1.27\n",
      "[info] Epoch:  15 | train loss: -22.12 | time: 1.26\n",
      "[info] evaluate task 4 takes 55.2 seconds\n",
      "[info] Epoch:  15 | succ: 0.80 ± 0.35 | best succ: 0.8 | succ. AoC 0.45 | time: 0.92\n",
      "[info] Epoch:  16 | train loss: -22.37 | time: 1.26\n",
      "[info] Epoch:  17 | train loss: -22.58 | time: 1.27\n",
      "[info] Epoch:  18 | train loss: -22.76 | time: 1.27\n",
      "[info] Epoch:  19 | train loss: -22.93 | time: 1.27\n",
      "[info] Epoch:  20 | train loss: -23.10 | time: 1.27\n",
      "[info] evaluate task 4 takes 64.8 seconds\n",
      "[info] Epoch:  20 | succ: 0.60 ± 0.43 | best succ: 0.8 | succ. AoC 0.52 | time: 1.08\n",
      "[info] Epoch:  21 | train loss: -23.22 | time: 1.26\n",
      "[info] Epoch:  22 | train loss: -23.36 | time: 1.26\n",
      "[info] Epoch:  23 | train loss: -23.44 | time: 1.26\n",
      "[info] Epoch:  24 | train loss: -23.51 | time: 1.27\n",
      "[info] Epoch:  25 | train loss: -23.59 | time: 1.27\n",
      "[info] evaluate task 4 takes 52.3 seconds\n",
      "[info] Epoch:  25 | succ: 0.80 ± 0.35 | best succ: 0.8 | succ. AoC 0.57 | time: 0.87\n",
      "[info] evaluate task 0 takes 106.3 seconds\n",
      "[info] evaluate task 1 takes 107.7 seconds\n",
      "[info] evaluate task 2 takes 109.5 seconds\n",
      "[info] evaluate task 3 takes 108.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [3:35:12<3:42:53, 2674.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] evaluate task 4 takes 52.7 seconds\n",
      "[info] Epoch:   0 | train loss: -2.67 | time: 0.58\n",
      "[info] evaluate task 5 takes 108.5 seconds\n",
      "[info] Epoch:   0 | succ: 0.00 ± 0.00 | best succ: 0.0 | succ. AoC 0.00 | time: 1.81\n",
      "[info] Epoch:   1 | train loss: -16.63 | time: 1.21\n",
      "[info] Epoch:   2 | train loss: -17.75 | time: 1.23\n",
      "[info] Epoch:   3 | train loss: -18.16 | time: 1.23\n",
      "[info] Epoch:   4 | train loss: -18.58 | time: 1.23\n",
      "[info] Epoch:   5 | train loss: -18.98 | time: 1.24\n",
      "[info] evaluate task 5 takes 68.5 seconds\n",
      "[info] Epoch:   5 | succ: 0.60 ± 0.43 | best succ: 0.6 | succ. AoC 0.30 | time: 1.14\n",
      "[info] Epoch:   6 | train loss: -19.26 | time: 1.21\n",
      "[info] Epoch:   7 | train loss: -19.62 | time: 1.22\n",
      "[info] Epoch:   8 | train loss: -19.95 | time: 1.24\n",
      "[info] Epoch:   9 | train loss: -20.17 | time: 1.24\n",
      "[info] Epoch:  10 | train loss: -20.52 | time: 1.23\n",
      "[info] evaluate task 5 takes 46.0 seconds\n",
      "[info] Epoch:  10 | succ: 1.00 ± 0.00 | best succ: 1.0 | succ. AoC 0.53 | time: 0.77\n",
      "[info] Epoch:  11 | train loss: -20.73 | time: 1.23\n",
      "[info] Epoch:  12 | train loss: -20.98 | time: 1.23\n",
      "[info] Epoch:  13 | train loss: -21.28 | time: 1.23\n",
      "[info] Epoch:  14 | train loss: -21.50 | time: 1.23\n",
      "[info] Epoch:  15 | train loss: -21.73 | time: 1.23\n",
      "[info] evaluate task 5 takes 58.5 seconds\n",
      "[info] Epoch:  15 | succ: 0.80 ± 0.35 | best succ: 1.0 | succ. AoC 0.65 | time: 0.97\n",
      "[info] Epoch:  16 | train loss: -21.88 | time: 1.22\n",
      "[info] Epoch:  17 | train loss: -22.15 | time: 1.22\n",
      "[info] Epoch:  18 | train loss: -22.33 | time: 1.24\n",
      "[info] Epoch:  19 | train loss: -22.51 | time: 1.26\n",
      "[info] Epoch:  20 | train loss: -22.64 | time: 1.24\n",
      "[info] evaluate task 5 takes 57.5 seconds\n",
      "[info] Epoch:  20 | succ: 0.80 ± 0.35 | best succ: 1.0 | succ. AoC 0.72 | time: 0.96\n",
      "[info] Epoch:  21 | train loss: -22.77 | time: 1.24\n",
      "[info] Epoch:  22 | train loss: -22.86 | time: 1.26\n",
      "[info] Epoch:  23 | train loss: -22.94 | time: 1.26\n",
      "[info] Epoch:  24 | train loss: -23.05 | time: 1.24\n",
      "[info] Epoch:  25 | train loss: -23.09 | time: 1.27\n",
      "[info] evaluate task 5 takes 62.0 seconds\n",
      "[info] Epoch:  25 | succ: 0.80 ± 0.35 | best succ: 1.0 | succ. AoC 0.77 | time: 1.03\n",
      "[info] evaluate task 0 takes 105.9 seconds\n",
      "[info] evaluate task 1 takes 109.7 seconds\n",
      "[info] evaluate task 2 takes 105.9 seconds\n",
      "[info] evaluate task 3 takes 33.0 seconds\n",
      "[info] evaluate task 4 takes 104.3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [4:24:02<3:04:06, 2761.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] evaluate task 5 takes 53.1 seconds\n",
      "[info] Epoch:   0 | train loss: 10.09 | time: 0.57\n",
      "[info] evaluate task 6 takes 107.1 seconds\n",
      "[info] Epoch:   0 | succ: 0.00 ± 0.00 | best succ: 0.0 | succ. AoC 0.00 | time: 1.79\n",
      "[info] Epoch:   1 | train loss: -16.66 | time: 1.22\n",
      "[info] Epoch:   2 | train loss: -17.90 | time: 1.22\n",
      "[info] Epoch:   3 | train loss: -18.42 | time: 1.23\n",
      "[info] Epoch:   4 | train loss: -18.89 | time: 1.23\n",
      "[info] Epoch:   5 | train loss: -19.28 | time: 1.23\n",
      "[info] evaluate task 6 takes 89.7 seconds\n",
      "[info] Epoch:   5 | succ: 0.20 ± 0.35 | best succ: 0.2 | succ. AoC 0.10 | time: 1.50\n",
      "[info] Epoch:   6 | train loss: -19.69 | time: 1.22\n",
      "[info] Epoch:   7 | train loss: -20.03 | time: 1.23\n",
      "[info] Epoch:   8 | train loss: -20.33 | time: 1.23\n",
      "[info] Epoch:   9 | train loss: -20.61 | time: 1.23\n",
      "[info] Epoch:  10 | train loss: -20.87 | time: 1.23\n",
      "[info] evaluate task 6 takes 102.4 seconds\n",
      "[info] Epoch:  10 | succ: 0.00 ± 0.00 | best succ: 0.2 | succ. AoC 0.13 | time: 1.71\n",
      "[info] Epoch:  11 | train loss: -21.17 | time: 1.22\n",
      "[info] Epoch:  12 | train loss: -21.49 | time: 1.23\n",
      "[info] Epoch:  13 | train loss: -21.69 | time: 1.23\n",
      "[info] Epoch:  14 | train loss: -21.90 | time: 1.23\n",
      "[info] Epoch:  15 | train loss: -22.16 | time: 1.23\n",
      "[info] evaluate task 6 takes 65.0 seconds\n",
      "[info] Epoch:  15 | succ: 0.60 ± 0.43 | best succ: 0.6 | succ. AoC 0.20 | time: 1.08\n",
      "[info] Epoch:  16 | train loss: -22.37 | time: 1.22\n",
      "[info] Epoch:  17 | train loss: -22.60 | time: 1.23\n",
      "[info] Epoch:  18 | train loss: -22.71 | time: 1.23\n",
      "[info] Epoch:  19 | train loss: -22.94 | time: 1.24\n",
      "[info] Epoch:  20 | train loss: -23.07 | time: 1.23\n",
      "[info] evaluate task 6 takes 66.9 seconds\n",
      "[info] Epoch:  20 | succ: 0.60 ± 0.43 | best succ: 0.6 | succ. AoC 0.28 | time: 1.11\n",
      "[info] Epoch:  21 | train loss: -23.18 | time: 1.22\n",
      "[info] Epoch:  22 | train loss: -23.30 | time: 1.23\n",
      "[info] Epoch:  23 | train loss: -23.40 | time: 1.23\n",
      "[info] Epoch:  24 | train loss: -23.47 | time: 1.23\n",
      "[info] Epoch:  25 | train loss: -23.50 | time: 1.23\n",
      "[info] evaluate task 6 takes 78.0 seconds\n",
      "[info] Epoch:  25 | succ: 0.40 ± 0.43 | best succ: 0.6 | succ. AoC 0.33 | time: 1.30\n",
      "[info] evaluate task 0 takes 105.5 seconds\n",
      "[info] evaluate task 1 takes 106.6 seconds\n",
      "[info] evaluate task 2 takes 104.8 seconds\n",
      "[info] evaluate task 3 takes 101.1 seconds\n",
      "[info] evaluate task 4 takes 92.5 seconds\n",
      "[info] evaluate task 5 takes 101.2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [5:17:38<2:25:30, 2910.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] evaluate task 6 takes 76.7 seconds\n",
      "[info] Epoch:   0 | train loss: 11.02 | time: 0.53\n",
      "[info] evaluate task 7 takes 103.9 seconds\n",
      "[info] Epoch:   0 | succ: 0.00 ± 0.00 | best succ: 0.0 | succ. AoC 0.00 | time: 1.73\n",
      "[info] Epoch:   1 | train loss: -16.80 | time: 1.12\n",
      "[info] Epoch:   2 | train loss: -18.12 | time: 1.13\n",
      "[info] Epoch:   3 | train loss: -18.80 | time: 1.13\n",
      "[info] Epoch:   4 | train loss: -19.26 | time: 1.13\n",
      "[info] Epoch:   5 | train loss: -19.79 | time: 1.14\n",
      "[info] evaluate task 7 takes 48.8 seconds\n",
      "[info] Epoch:   5 | succ: 0.80 ± 0.35 | best succ: 0.8 | succ. AoC 0.40 | time: 0.81\n",
      "[info] Epoch:   6 | train loss: -20.14 | time: 1.13\n",
      "[info] Epoch:   7 | train loss: -20.53 | time: 1.14\n",
      "[info] Epoch:   8 | train loss: -20.87 | time: 1.14\n",
      "[info] Epoch:   9 | train loss: -21.19 | time: 1.14\n",
      "[info] Epoch:  10 | train loss: -21.49 | time: 1.14\n",
      "[info] evaluate task 7 takes 63.7 seconds\n",
      "[info] Epoch:  10 | succ: 0.60 ± 0.43 | best succ: 0.8 | succ. AoC 0.53 | time: 1.06\n",
      "[info] Epoch:  11 | train loss: -21.81 | time: 1.13\n",
      "[info] Epoch:  12 | train loss: -22.06 | time: 1.14\n",
      "[info] Epoch:  13 | train loss: -22.29 | time: 1.14\n",
      "[info] Epoch:  14 | train loss: -22.51 | time: 1.14\n",
      "[info] Epoch:  15 | train loss: -22.77 | time: 1.14\n",
      "[info] evaluate task 7 takes 89.2 seconds\n",
      "[info] Epoch:  15 | succ: 0.20 ± 0.35 | best succ: 0.8 | succ. AoC 0.60 | time: 1.49\n",
      "[info] Epoch:  16 | train loss: -22.97 | time: 1.13\n",
      "[info] Epoch:  17 | train loss: -23.15 | time: 1.14\n",
      "[info] Epoch:  18 | train loss: -23.35 | time: 1.14\n",
      "[info] Epoch:  19 | train loss: -23.47 | time: 1.14\n",
      "[info] Epoch:  20 | train loss: -23.67 | time: 1.14\n",
      "[info] evaluate task 7 takes 76.1 seconds\n",
      "[info] Epoch:  20 | succ: 0.40 ± 0.43 | best succ: 0.8 | succ. AoC 0.64 | time: 1.27\n",
      "[info] Epoch:  21 | train loss: -23.76 | time: 1.15\n",
      "[info] Epoch:  22 | train loss: -23.88 | time: 1.22\n",
      "[info] Epoch:  23 | train loss: -23.97 | time: 1.23\n",
      "[info] Epoch:  24 | train loss: -24.06 | time: 1.22\n",
      "[info] Epoch:  25 | train loss: -24.11 | time: 1.22\n",
      "[info] evaluate task 7 takes 85.6 seconds\n",
      "[info] Epoch:  25 | succ: 0.40 ± 0.43 | best succ: 0.8 | succ. AoC 0.67 | time: 1.43\n",
      "[info] evaluate task 0 takes 83.1 seconds\n",
      "[info] evaluate task 1 takes 109.1 seconds\n",
      "[info] evaluate task 2 takes 108.1 seconds\n",
      "[info] evaluate task 3 takes 108.5 seconds\n",
      "[info] evaluate task 4 takes 68.3 seconds\n",
      "[info] evaluate task 5 takes 109.7 seconds\n",
      "[info] evaluate task 6 takes 96.3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [6:10:06<1:39:31, 2985.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] evaluate task 7 takes 65.3 seconds\n",
      "[info] Epoch:   0 | train loss: -7.76 | time: 0.62\n",
      "[info] evaluate task 8 takes 110.4 seconds\n",
      "[info] Epoch:   0 | succ: 0.00 ± 0.00 | best succ: 0.0 | succ. AoC 0.00 | time: 1.84\n",
      "[info] Epoch:   1 | train loss: -17.95 | time: 1.32\n",
      "[info] Epoch:   2 | train loss: -18.97 | time: 1.33\n",
      "[info] Epoch:   3 | train loss: -19.41 | time: 1.34\n",
      "[info] Epoch:   4 | train loss: -19.73 | time: 1.35\n",
      "[info] Epoch:   5 | train loss: -20.18 | time: 1.33\n",
      "[info] evaluate task 8 takes 68.3 seconds\n",
      "[info] Epoch:   5 | succ: 0.60 ± 0.43 | best succ: 0.6 | succ. AoC 0.30 | time: 1.14\n",
      "[info] Epoch:   6 | train loss: -20.51 | time: 1.33\n",
      "[info] Epoch:   7 | train loss: -20.74 | time: 1.35\n",
      "[info] Epoch:   8 | train loss: -21.01 | time: 1.36\n",
      "[info] Epoch:   9 | train loss: -21.28 | time: 1.34\n",
      "[info] Epoch:  10 | train loss: -21.57 | time: 1.34\n",
      "[info] evaluate task 8 takes 51.7 seconds\n",
      "[info] Epoch:  10 | succ: 0.80 ± 0.35 | best succ: 0.8 | succ. AoC 0.47 | time: 0.86\n",
      "[info] Epoch:  11 | train loss: -21.80 | time: 1.32\n",
      "[info] Epoch:  12 | train loss: -22.06 | time: 1.33\n",
      "[info] Epoch:  13 | train loss: -22.23 | time: 1.33\n",
      "[info] Epoch:  14 | train loss: -22.50 | time: 1.33\n",
      "[info] Epoch:  15 | train loss: -22.82 | time: 1.34\n",
      "[info] evaluate task 8 takes 41.1 seconds\n",
      "[info] Epoch:  15 | succ: 1.00 ± 0.00 | best succ: 1.0 | succ. AoC 0.60 | time: 0.69\n",
      "[info] Epoch:  16 | train loss: -22.89 | time: 1.38\n",
      "[info] Epoch:  17 | train loss: -23.16 | time: 1.40\n",
      "[info] Epoch:  18 | train loss: -23.36 | time: 1.40\n",
      "[info] Epoch:  19 | train loss: -23.47 | time: 1.36\n",
      "[info] Epoch:  20 | train loss: -23.65 | time: 1.35\n",
      "[info] evaluate task 8 takes 39.6 seconds\n",
      "[info] Epoch:  20 | succ: 1.00 ± 0.00 | best succ: 1.0 | succ. AoC 0.68 | time: 0.66\n",
      "[info] Epoch:  21 | train loss: -23.77 | time: 1.34\n",
      "[info] Epoch:  22 | train loss: -23.90 | time: 1.38\n",
      "[info] Epoch:  23 | train loss: -23.99 | time: 1.38\n",
      "[info] Epoch:  24 | train loss: -24.10 | time: 1.37\n",
      "[info] Epoch:  25 | train loss: -24.17 | time: 1.34\n",
      "[info] evaluate task 8 takes 54.1 seconds\n",
      "[info] Epoch:  25 | succ: 0.80 ± 0.35 | best succ: 1.0 | succ. AoC 0.73 | time: 0.90\n",
      "[info] evaluate task 0 takes 106.3 seconds\n",
      "[info] evaluate task 1 takes 105.2 seconds\n",
      "[info] evaluate task 2 takes 104.6 seconds\n",
      "[info] evaluate task 3 takes 104.8 seconds\n",
      "[info] evaluate task 4 takes 103.5 seconds\n",
      "[info] evaluate task 5 takes 104.0 seconds\n",
      "[info] evaluate task 6 takes 78.3 seconds\n",
      "[info] evaluate task 7 takes 104.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [7:08:19<52:24, 3144.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] evaluate task 8 takes 55.9 seconds\n",
      "[info] Epoch:   0 | train loss: 49.85 | time: 0.54\n",
      "[info] evaluate task 9 takes 105.7 seconds\n",
      "[info] Epoch:   0 | succ: 0.00 ± 0.00 | best succ: 0.0 | succ. AoC 0.00 | time: 1.76\n",
      "[info] Epoch:   1 | train loss: -17.30 | time: 1.08\n",
      "[info] Epoch:   2 | train loss: -18.84 | time: 1.08\n",
      "[info] Epoch:   3 | train loss: -19.23 | time: 1.09\n",
      "[info] Epoch:   4 | train loss: -19.55 | time: 1.09\n",
      "[info] Epoch:   5 | train loss: -19.99 | time: 1.10\n",
      "[info] evaluate task 9 takes 34.9 seconds\n",
      "[info] Epoch:   5 | succ: 1.00 ± 0.00 | best succ: 1.0 | succ. AoC 0.50 | time: 0.58\n",
      "[info] Epoch:   6 | train loss: -20.42 | time: 1.10\n",
      "[info] Epoch:   7 | train loss: -20.64 | time: 1.10\n",
      "[info] Epoch:   8 | train loss: -21.00 | time: 1.09\n",
      "[info] Epoch:   9 | train loss: -21.22 | time: 1.09\n",
      "[info] Epoch:  10 | train loss: -21.49 | time: 1.09\n",
      "[info] evaluate task 9 takes 65.4 seconds\n",
      "[info] Epoch:  10 | succ: 0.60 ± 0.43 | best succ: 1.0 | succ. AoC 0.67 | time: 1.09\n",
      "[info] Epoch:  11 | train loss: -21.96 | time: 1.09\n",
      "[info] Epoch:  12 | train loss: -22.12 | time: 1.09\n",
      "[info] Epoch:  13 | train loss: -22.42 | time: 1.09\n",
      "[info] Epoch:  14 | train loss: -22.65 | time: 1.09\n",
      "[info] Epoch:  15 | train loss: -22.94 | time: 1.10\n",
      "[info] evaluate task 9 takes 34.6 seconds\n",
      "[info] Epoch:  15 | succ: 1.00 ± 0.00 | best succ: 1.0 | succ. AoC 0.75 | time: 0.58\n",
      "[info] Epoch:  16 | train loss: -23.13 | time: 1.09\n",
      "[info] Epoch:  17 | train loss: -23.37 | time: 1.09\n",
      "[info] Epoch:  18 | train loss: -23.52 | time: 1.09\n",
      "[info] Epoch:  19 | train loss: -23.68 | time: 1.09\n",
      "[info] Epoch:  20 | train loss: -23.85 | time: 1.09\n",
      "[info] evaluate task 9 takes 35.8 seconds\n",
      "[info] Epoch:  20 | succ: 1.00 ± 0.00 | best succ: 1.0 | succ. AoC 0.80 | time: 0.60\n",
      "[info] Epoch:  21 | train loss: -23.98 | time: 1.09\n",
      "[info] Epoch:  22 | train loss: -24.09 | time: 1.09\n",
      "[info] Epoch:  23 | train loss: -24.21 | time: 1.09\n",
      "[info] Epoch:  24 | train loss: -24.32 | time: 1.10\n",
      "[info] Epoch:  25 | train loss: -24.40 | time: 1.09\n",
      "[info] evaluate task 9 takes 49.9 seconds\n",
      "[info] Epoch:  25 | succ: 0.80 ± 0.35 | best succ: 1.0 | succ. AoC 0.83 | time: 0.83\n",
      "[info] evaluate task 0 takes 110.0 seconds\n",
      "[info] evaluate task 1 takes 110.4 seconds\n",
      "[info] evaluate task 2 takes 72.3 seconds\n",
      "[info] evaluate task 3 takes 93.2 seconds\n",
      "[info] evaluate task 4 takes 106.4 seconds\n",
      "[info] evaluate task 5 takes 103.6 seconds\n",
      "[info] evaluate task 6 takes 106.1 seconds\n",
      "[info] evaluate task 7 takes 104.8 seconds\n",
      "[info] evaluate task 8 takes 104.3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [8:00:57<00:00, 2885.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] evaluate task 9 takes 33.5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cfg.policy.policy_type = \"MyTransformerPolicy\"\n",
    "cfg.lifelong.algo = \"MyLifelongAlgo\"\n",
    "\n",
    "create_experiment_dir(cfg)\n",
    "cfg.shape_meta = shape_meta\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from libero.lifelong.metric import evaluate_loss, evaluate_success\n",
    "\n",
    "print(\"experiment directory is: \", cfg.experiment_dir)\n",
    "algo = safe_device(MyLifelongAlgo(n_tasks, cfg), cfg.device)\n",
    "\n",
    "result_summary = {\n",
    "    'L_conf_mat': np.zeros((n_tasks, n_tasks)),   # loss confusion matrix\n",
    "    'S_conf_mat': np.zeros((n_tasks, n_tasks)),   # success confusion matrix\n",
    "    'L_fwd'     : np.zeros((n_tasks,)),           # loss AUC, how fast the agent learns\n",
    "    'S_fwd'     : np.zeros((n_tasks,)),           # success AUC, how fast the agent succeeds\n",
    "}\n",
    "\n",
    "gsz = cfg.data.task_group_size\n",
    "\n",
    "if (cfg.train.n_epochs < 50):\n",
    "    print(\"NOTE: the number of epochs used in this example is intentionally reduced to 30 for simplicity.\")\n",
    "if (cfg.eval.n_eval < 20):\n",
    "    print(\"NOTE: the number of evaluation episodes used in this example is intentionally reduced to 5 for simplicity.\")\n",
    "\n",
    "for i in trange(n_tasks):\n",
    "    algo.train()\n",
    "    s_fwd, l_fwd = algo.learn_one_task(datasets[i], i, benchmark, result_summary)\n",
    "    # s_fwd is success rate AUC, when the agent learns the {0, e, 2e, ...} epochs\n",
    "    # l_fwd is BC loss AUC, similar to s_fwd\n",
    "    result_summary[\"S_fwd\"][i] = s_fwd\n",
    "    result_summary[\"L_fwd\"][i] = l_fwd\n",
    "\n",
    "    if cfg.eval.eval:\n",
    "        algo.eval()\n",
    "        # we only evaluate on the past tasks: 0 .. i\n",
    "        L = evaluate_loss(cfg, algo, benchmark, datasets[:i+1]) # (i+1,)\n",
    "        S = evaluate_success(cfg, algo, benchmark, list(range((i+1)*gsz))) # (i+1,)\n",
    "        result_summary[\"L_conf_mat\"][i][:i+1] = L\n",
    "        result_summary[\"S_conf_mat\"][i][:i+1] = S\n",
    "\n",
    "        torch.save(result_summary, os.path.join(cfg.experiment_dir, f'result.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6 0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.8 0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.8 0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.2 0.6 0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.8 0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1.  0.  0.8 0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.2 0.  0.4 0.  0.  0. ]\n",
      " [0.4 0.  0.  0.  0.8 0.  0.2 0.6 0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.4 0.  0.8 0. ]\n",
      " [0.  0.  0.8 0.2 0.  0.  0.  0.  0.  1. ]]\n",
      "[0.5        0.63333333 0.66666667 0.33333333 0.56666667 0.76666667\n",
      " 0.33333333 0.66666667 0.73333333 0.83333333]\n"
     ]
    }
   ],
   "source": [
    "result_summary = torch.load(os.path.join(cfg.experiment_dir, f'result.pt'))\n",
    "print(result_summary[\"S_conf_mat\"])\n",
    "print(result_summary[\"S_fwd\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Compute FWT, BWT, and AUC of the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "benchmark_map = {\n",
    "    \"libero_10\"     : \"LIBERO_10\",\n",
    "    \"libero_90\"     : \"LIBERO_90\",\n",
    "    \"libero_spatial\": \"LIBERO_SPATIAL\",\n",
    "    \"libero_object\" : \"LIBERO_OBJECT\",\n",
    "    \"libero_goal\"   : \"LIBERO_GOAL\",\n",
    "}\n",
    "\n",
    "algo_map = {\n",
    "    \"base\"     : \"Sequential\",\n",
    "    \"er\"       : \"ER\",\n",
    "    \"ewc\"      : \"EWC\",\n",
    "    \"packnet\"  : \"PackNet\",\n",
    "    \"multitask\": \"Multitask\",\n",
    "    \"custom_algo\"   : \"MyLifelongAlgo\",\n",
    "}\n",
    "\n",
    "policy_map = {\n",
    "    \"bc_rnn_policy\"        : \"BCRNNPolicy\",\n",
    "    \"bc_transformer_policy\": \"BCTransformerPolicy\",\n",
    "    \"bc_vilt_policy\"       : \"BCViLTPolicy\",\n",
    "    \"custom_policy\"        : \"MyTransformerPolicy\",\n",
    "}\n",
    "\n",
    "seeds = [10000]\n",
    "N_SEEDS = len(seeds)\n",
    "N_TASKS = 10\n",
    "\n",
    "def get_auc(experiment_dir, bench, algo, policy):\n",
    "    N_EP = cfg.train.n_epochs // cfg.eval.eval_every + 1\n",
    "    fwds = np.zeros((N_TASKS, N_EP, N_SEEDS))\n",
    "\n",
    "    for task in range(N_TASKS):\n",
    "        counter = 0\n",
    "        for k, seed in enumerate(seeds):\n",
    "            name = f\"{experiment_dir}/task{task}_auc.log\"\n",
    "            try:\n",
    "                succ = torch.load(name)[\"success\"] # (n_epochs)\n",
    "                idx = succ.argmax()\n",
    "                succ[idx:] = succ[idx]\n",
    "                fwds[task, :, k] = succ\n",
    "            except:\n",
    "                print(\"Some errors when loading results\")\n",
    "                continue\n",
    "    return fwds\n",
    "\n",
    "def compute_metric(res):\n",
    "    mat, fwts  = res # fwds: (num_tasks, num_save_intervals, num_seeds)\n",
    "    num_tasks, num_seeds = mat.shape[1:]\n",
    "    ret = {}\n",
    "\n",
    "    # compute fwt\n",
    "    fwt = fwts.mean(axis=(0,1))\n",
    "    ret[\"fwt\"] = fwt\n",
    "    # compute bwt\n",
    "    bwts = []\n",
    "    aucs = []\n",
    "    for seed in range(num_seeds):\n",
    "        bwt = 0.0\n",
    "        auc = 0.0\n",
    "        for k in range(num_tasks):\n",
    "            bwt_k = 0.0\n",
    "            auc_k = 0.0\n",
    "            for tau in range(k+1, num_tasks):\n",
    "                bwt_k += mat[k,k,seed] - mat[tau,k,seed]\n",
    "                auc_k += mat[tau,k,seed]\n",
    "            if k + 1 < num_tasks:\n",
    "                bwt_k /= (num_tasks - k - 1)\n",
    "            auc_k = (auc_k + fwts[k,:,seed].mean()) / (num_tasks - k)\n",
    "\n",
    "            bwt += bwt_k\n",
    "            auc += auc_k\n",
    "        bwts.append(bwt / num_tasks)\n",
    "        aucs.append(auc / num_tasks)\n",
    "    bwts = np.array(bwts)\n",
    "    aucs = np.array(aucs)\n",
    "    ret[\"bwt\"] = bwts\n",
    "    ret[\"auc\"] = aucs\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fwt': array([0.60333333]), 'bwt': array([0.54126984]), 'auc': array([0.26577513])}\n"
     ]
    }
   ],
   "source": [
    "experiment_dir = \"experiments\"\n",
    "benchmark_name = \"libero_object\"\n",
    "algo_name = \"custom_algo\"\n",
    "policy_name = \"custom_policy\"\n",
    "\n",
    "fwds = get_auc(cfg.experiment_dir, benchmark_name, algo_name, policy_name)\n",
    "\n",
    "conf_mat = result_summary[\"S_conf_mat\"][..., np.newaxis]\n",
    "\n",
    "metric = compute_metric((conf_mat, fwds))\n",
    "print(metric)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Visualize policy rollouts\n",
    "\n",
    " This is an example of how to use the trained model to do inference. We will take the policy from training on the first task as an example. More concrete example, please see `evaluate_one_task_success` in the file `lifelong/lifelong/metric.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m action \u001b[39m=\u001b[39m algo\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mget_action(data)\n\u001b[1;32m     58\u001b[0m obs, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m---> 59\u001b[0m obs_tensors[k]\u001b[39m.\u001b[39mappend(obs[\u001b[39m\"\u001b[39m\u001b[39magentview_image\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     61\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(env_num):\n\u001b[1;32m     62\u001b[0m     dones[k] \u001b[39m=\u001b[39m dones[k] \u001b[39mor\u001b[39;00m done[k]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "from libero.libero.envs import OffScreenRenderEnv, DummyVectorEnv\n",
    "from libero.lifelong.metric import raw_obs_to_tensor_obs\n",
    "\n",
    "# You can turn on subprocess\n",
    "env_num = 1\n",
    "action_dim = 7\n",
    "\n",
    "\n",
    "# If it's packnet, the weights need to be processed first\n",
    "task_id = 0\n",
    "task = benchmark.get_task(task_id)\n",
    "task_emb = benchmark.get_task_emb(task_id)\n",
    "\n",
    "if cfg.lifelong.algo == \"PackNet\":\n",
    "    algo = algo.get_eval_algo(task_id)\n",
    "\n",
    "algo.eval()\n",
    "env_args = {\n",
    "    \"bddl_file_name\": os.path.join(\n",
    "        cfg.bddl_folder, task.problem_folder, task.bddl_file\n",
    "    ),\n",
    "    \"camera_heights\": cfg.data.img_h,\n",
    "    \"camera_widths\": cfg.data.img_w,\n",
    "}\n",
    "\n",
    "env = DummyVectorEnv(\n",
    "            [lambda: OffScreenRenderEnv(**env_args) for _ in range(env_num)]\n",
    ")\n",
    "\n",
    "init_states_path = os.path.join(\n",
    "    cfg.init_states_folder, task.problem_folder, task.init_states_file\n",
    ")\n",
    "init_states = torch.load(init_states_path)\n",
    "\n",
    "env.reset()\n",
    "\n",
    "init_state = init_states[0:1]\n",
    "dones = [False]\n",
    "\n",
    "algo.reset()\n",
    "\n",
    "obs = env.set_init_state(init_state)\n",
    "\n",
    "\n",
    "# Make sure the gripepr is open to make it consistent with the provided demos.\n",
    "dummy_actions = np.zeros((env_num, action_dim))\n",
    "for _ in range(5):\n",
    "    obs, _, _, _ = env.step(dummy_actions)\n",
    "\n",
    "steps = 0\n",
    "\n",
    "obs_tensors = [[]] * env_num\n",
    "while steps < cfg.eval.max_steps:\n",
    "    steps += 1\n",
    "    data = raw_obs_to_tensor_obs(obs, task_emb, cfg)\n",
    "    action = algo.policy.get_action(data)\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "    for k in range(env_num):\n",
    "        dones[k] = dones[k] or done[k]\n",
    "        obs_tensors[k].append(obs[k][\"agentview_image\"])\n",
    "    if all(dones):\n",
    "        break\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(obs_tensors[0][0])\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
